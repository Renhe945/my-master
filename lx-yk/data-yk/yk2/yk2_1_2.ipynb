{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T02:41:43.368082Z",
     "start_time": "2024-10-04T02:41:41.038865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 题目2 电影推荐（共计52分）\n",
    "# 其中数据见《sample_movielens_ratings.txt》/\n",
    "# 其中的格式说明如下\n",
    "# 0::2::3::1424380312\n",
    "# 对应为 用户：电影：打分：打分时间\n",
    "\n",
    "# 请进行推荐系统的开发\n",
    "# 1  导入相关的库（4分）\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import KNNBasic\n",
    "#from surprise import accuracy\n",
    "# 2  自行定义基于物品或者用户推荐的函数（4分）# 对应为 用户：电影：打分：打分时间\n",
    "#用户\n",
    "def t2_wp(user_id,x,y,k=10):\n",
    "    # 实例化KNNBasic算法，并设置基于用户的相似度选项  \n",
    "    # 这将计算用户之间的相似度分数  \n",
    "    o1=KNNBasic(sim_options={'jy':True})\n",
    "    o1.fit(x)\n",
    "    o2=o1.test(y)\n",
    "    # 过滤预测结果，只保留指定用户的预测  \n",
    "    user=[i for i in o2 if i.uid==user_id]\n",
    "    user.sort(key=lambda x: x.est,reverse=True)\n",
    "     # 返回用户的前k个推荐物品的物品ID列表  \n",
    "    return [pred.iid for pred in user[:k]],o2\n",
    "#物品\n",
    "def t2_yh(item_id,x,y,k=10):\n",
    "    # 实例化KNNBasic算法，并设置基于用户的相似度选项  \n",
    "    # 这将计算用户之间的相似度分数  \n",
    "    model = KNNBasic(sim_options={'user_based': False})      #改关键参数  \n",
    "    # 计算用户和物品之间的相似度 \n",
    "    model.fit(x)     \n",
    "    # 在反测试集上测试算法，以获取物品的预测评分  \n",
    "    predictions = model.test(y)   \n",
    "    # 过滤预测结果，只保留指定物品的预测  \n",
    "    item_predictions = [pred for pred in predictions if pred.iid == item_id]    \n",
    "    # 根据估计的评分以降序方式对物品的预测进行排序  # 这会将用户从最推荐到最不推荐进行排名 \n",
    "    item_predictions.sort(key=lambda x: x.est, reverse=True)    \n",
    "    # 返回用户的前k个推荐物品的用户ID列表  \n",
    "    return [pred.uid for pred in item_predictions[:k]],predictions\n"
   ],
   "id": "765fc56eebdac290",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T02:45:08.491658Z",
     "start_time": "2024-10-04T02:45:08.439306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 测试 用KNN算法进行训练加预测得到的DataFrame 类型字段\n",
    "from surprise import Dataset, Reader\n",
    "read = Reader(rating_scale=(1,5),sep='::')\n",
    "dataset = Dataset.load_from_file(\"E:///python代码/lx-yk/data-yk/yk2/sample_movielens_ratings.txt\",read)\n",
    "x,y = train_test_split(dataset,test_size=0.2,random_state=42)\n",
    "knn = KNNBasic(sim_options={'user_based': True})\n",
    "knn.fit(x)\n",
    "test_pred = knn.test(y)\n",
    "# 默认的字段名 uid,iid,r_ui,est,details\n",
    "dd = pd.DataFrame(test_pred)\n",
    "dd"
   ],
   "id": "ee8e5dc5eac3e7c0",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array array(<surprise.dataset.DatasetAutoFolds object at 0x00000280F3FE8890>,\n      dtype=object) cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m read \u001B[38;5;241m=\u001B[39m Reader(rating_scale\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m5\u001B[39m),sep\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m::\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      5\u001B[0m dataset \u001B[38;5;241m=\u001B[39m Dataset\u001B[38;5;241m.\u001B[39mload_from_file(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mE:///python代码/lx-yk/data-yk/yk2/sample_movielens_ratings.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m,read)\n\u001B[1;32m----> 6\u001B[0m x,y \u001B[38;5;241m=\u001B[39m train_test_split(dataset,test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m,random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m      7\u001B[0m knn \u001B[38;5;241m=\u001B[39m KNNBasic(sim_options\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muser_based\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28;01mTrue\u001B[39;00m})\n\u001B[0;32m      8\u001B[0m knn\u001B[38;5;241m.\u001B[39mfit(x)\n",
      "File \u001B[1;32mD:\\Jupyter\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    211\u001B[0m         )\n\u001B[0;32m    212\u001B[0m     ):\n\u001B[1;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    223\u001B[0m     )\n",
      "File \u001B[1;32mD:\\Jupyter\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2657\u001B[0m, in \u001B[0;36mtrain_test_split\u001B[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001B[0m\n\u001B[0;32m   2654\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_arrays \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   2655\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAt least one array required as input\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 2657\u001B[0m arrays \u001B[38;5;241m=\u001B[39m indexable(\u001B[38;5;241m*\u001B[39marrays)\n\u001B[0;32m   2659\u001B[0m n_samples \u001B[38;5;241m=\u001B[39m _num_samples(arrays[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m   2660\u001B[0m n_train, n_test \u001B[38;5;241m=\u001B[39m _validate_shuffle_split(\n\u001B[0;32m   2661\u001B[0m     n_samples, test_size, train_size, default_test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.25\u001B[39m\n\u001B[0;32m   2662\u001B[0m )\n",
      "File \u001B[1;32mD:\\Jupyter\\Lib\\site-packages\\sklearn\\utils\\validation.py:514\u001B[0m, in \u001B[0;36mindexable\u001B[1;34m(*iterables)\u001B[0m\n\u001B[0;32m    484\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001B[39;00m\n\u001B[0;32m    485\u001B[0m \n\u001B[0;32m    486\u001B[0m \u001B[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    510\u001B[0m \u001B[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <3x1 sparse matrix ...>]\u001B[39;00m\n\u001B[0;32m    511\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    513\u001B[0m result \u001B[38;5;241m=\u001B[39m [_make_indexable(X) \u001B[38;5;28;01mfor\u001B[39;00m X \u001B[38;5;129;01min\u001B[39;00m iterables]\n\u001B[1;32m--> 514\u001B[0m check_consistent_length(\u001B[38;5;241m*\u001B[39mresult)\n\u001B[0;32m    515\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32mD:\\Jupyter\\Lib\\site-packages\\sklearn\\utils\\validation.py:454\u001B[0m, in \u001B[0;36mcheck_consistent_length\u001B[1;34m(*arrays)\u001B[0m\n\u001B[0;32m    436\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcheck_consistent_length\u001B[39m(\u001B[38;5;241m*\u001B[39marrays):\n\u001B[0;32m    437\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Check that all arrays have consistent first dimensions.\u001B[39;00m\n\u001B[0;32m    438\u001B[0m \n\u001B[0;32m    439\u001B[0m \u001B[38;5;124;03m    Checks whether all objects in arrays have the same shape or length.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    451\u001B[0m \u001B[38;5;124;03m    >>> check_consistent_length(a, b)\u001B[39;00m\n\u001B[0;32m    452\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 454\u001B[0m     lengths \u001B[38;5;241m=\u001B[39m [_num_samples(X) \u001B[38;5;28;01mfor\u001B[39;00m X \u001B[38;5;129;01min\u001B[39;00m arrays \u001B[38;5;28;01mif\u001B[39;00m X \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m]\n\u001B[0;32m    455\u001B[0m     uniques \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(lengths)\n\u001B[0;32m    456\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(uniques) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[1;32mD:\\Jupyter\\Lib\\site-packages\\sklearn\\utils\\validation.py:382\u001B[0m, in \u001B[0;36m_num_samples\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m    380\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(x, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshape\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m x\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    381\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(x\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 382\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    383\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSingleton array \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m cannot be considered a valid collection.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m x\n\u001B[0;32m    384\u001B[0m         )\n\u001B[0;32m    385\u001B[0m     \u001B[38;5;66;03m# Check that shape is returning an integer or default to len\u001B[39;00m\n\u001B[0;32m    386\u001B[0m     \u001B[38;5;66;03m# Dask dataframes may not return numeric shape[0] value\u001B[39;00m\n\u001B[0;32m    387\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], numbers\u001B[38;5;241m.\u001B[39mIntegral):\n",
      "\u001B[1;31mTypeError\u001B[0m: Singleton array array(<surprise.dataset.DatasetAutoFolds object at 0x00000280F3FE8890>,\n      dtype=object) cannot be considered a valid collection."
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T05:49:41.370583Z",
     "start_time": "2024-10-04T05:49:40.482404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "## 其中数据见《sample_movielens_ratings.txt》/\n",
    "# 其中的格式说明如下\n",
    "# 0::2::3::1424380312\n",
    "# 对应为 用户：电影：打分：打分时间\n",
    "# 3  读取数据 其中用户 电影评分及评分时间为附件所示（4分）\n",
    "a1=pd.read_csv(\"E:///python代码/lx-yk/data-yk/yk2/sample_movielens_ratings.txt\",sep='::',engine='python',names=['用户','电影','打分','打分时间'])\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "x=a1.drop('打分时间',axis=1)\n",
    "# 划分训练集跟测试集\n",
    "y=a1['打分时间']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=42)\n",
    "\n",
    "\n",
    "# # 4  生成用户-物品评分矩阵（4分）\n",
    "a4 = X_train.pivot_table(index='用户', columns='电影', values='打分')\n",
    "print(a4)\n",
    "item_similarity_matrix = cosine_similarity(a4.T)\n",
    "print(item_similarity_matrix)\n",
    "# # 5  计算相似度：  \n",
    "# 从基于物品相似度计算（4分）\n",
    "\n",
    "#    从基于用户相似度计算（4分）\n",
    "# 6  进行相似度预测:调用第2步进行相似度计算\n",
    "# 从基于物品相似度计算（4分）\n",
    "#     从基于用户相似度计算（4分）\n",
    "# 7  显示给用户推荐的top10的电影（5分）\n",
    "# 8   进行性能评估并输出结果（5分）\n",
    "# 9  手动实现简单的逻辑回归算法（10分）"
   ],
   "id": "e42bc22ce6a837f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "电影   0    1    2    3    4    5    6    7    8    9   ...   90   91   92   93  \\\n",
      "用户                                                    ...                       \n",
      "0   NaN  NaN  3.0  1.0  NaN  2.0  NaN  NaN  NaN  4.0  ...  NaN  3.0  NaN  NaN   \n",
      "1   NaN  NaN  NaN  1.0  NaN  NaN  1.0  NaN  NaN  3.0  ...  NaN  1.0  2.0  1.0   \n",
      "2   NaN  NaN  NaN  NaN  3.0  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  4.0  5.0   \n",
      "3   1.0  1.0  1.0  NaN  NaN  NaN  NaN  3.0  3.0  1.0  ...  NaN  1.0  NaN  NaN   \n",
      "4   NaN  NaN  NaN  NaN  NaN  NaN  1.0  NaN  1.0  1.0  ...  NaN  NaN  NaN  NaN   \n",
      "5   NaN  1.0  NaN  NaN  1.0  1.0  NaN  NaN  1.0  3.0  ...  NaN  2.0  NaN  NaN   \n",
      "6   NaN  NaN  3.0  NaN  NaN  1.0  1.0  NaN  NaN  1.0  ...  NaN  2.0  NaN  NaN   \n",
      "7   NaN  NaN  NaN  NaN  1.0  NaN  NaN  1.0  NaN  NaN  ...  NaN  NaN  2.0  NaN   \n",
      "8   1.0  NaN  4.0  2.0  2.0  NaN  NaN  1.0  NaN  NaN  ...  1.0  NaN  2.0  NaN   \n",
      "9   NaN  NaN  3.0  1.0  1.0  1.0  1.0  NaN  NaN  NaN  ...  3.0  NaN  NaN  NaN   \n",
      "10  3.0  NaN  4.0  NaN  3.0  NaN  NaN  1.0  1.0  NaN  ...  1.0  NaN  NaN  NaN   \n",
      "11  1.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  1.0  ...  4.0  NaN  NaN  NaN   \n",
      "12  NaN  NaN  1.0  NaN  NaN  NaN  1.0  3.0  1.0  NaN  ...  NaN  3.0  1.0  NaN   \n",
      "13  NaN  NaN  NaN  NaN  2.0  1.0  1.0  NaN  NaN  NaN  ...  NaN  NaN  NaN  4.0   \n",
      "14  NaN  1.0  NaN  3.0  1.0  1.0  1.0  1.0  NaN  NaN  ...  NaN  NaN  NaN  NaN   \n",
      "15  1.0  4.0  1.0  NaN  NaN  NaN  1.0  NaN  NaN  NaN  ...  NaN  2.0  NaN  NaN   \n",
      "16  NaN  NaN  NaN  NaN  NaN  NaN  2.0  1.0  NaN  1.0  ...  5.0  NaN  NaN  1.0   \n",
      "17  NaN  NaN  NaN  1.0  NaN  NaN  1.0  NaN  NaN  NaN  ...  5.0  3.0  1.0  1.0   \n",
      "18  NaN  1.0  NaN  NaN  NaN  NaN  1.0  1.0  NaN  NaN  ...  NaN  NaN  NaN  NaN   \n",
      "19  1.0  1.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  4.0  NaN  NaN  NaN   \n",
      "20  1.0  1.0  2.0  NaN  2.0  NaN  NaN  NaN  1.0  NaN  ...  3.0  1.0  2.0  NaN   \n",
      "21  1.0  NaN  4.0  NaN  NaN  NaN  NaN  2.0  NaN  NaN  ...  NaN  NaN  2.0  NaN   \n",
      "22  1.0  NaN  NaN  2.0  NaN  NaN  2.0  NaN  NaN  1.0  ...  2.0  NaN  NaN  NaN   \n",
      "23  1.0  NaN  1.0  NaN  1.0  NaN  2.0  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN   \n",
      "24  NaN  NaN  NaN  NaN  1.0  NaN  3.0  1.0  NaN  NaN  ...  5.0  1.0  1.0  NaN   \n",
      "25  NaN  3.0  1.0  NaN  NaN  NaN  NaN  1.0  NaN  1.0  ...  NaN  NaN  1.0  NaN   \n",
      "26  1.0  1.0  1.0  NaN  NaN  2.0  3.0  5.0  NaN  NaN  ...  NaN  1.0  NaN  NaN   \n",
      "27  1.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  1.0  ...  NaN  1.0  1.0  1.0   \n",
      "28  NaN  1.0  4.0  1.0  NaN  NaN  1.0  1.0  NaN  NaN  ...  NaN  NaN  NaN  NaN   \n",
      "29  NaN  NaN  NaN  1.0  NaN  1.0  NaN  2.0  NaN  1.0  ...  NaN  NaN  NaN  1.0   \n",
      "\n",
      "电影   94   95   96   97   98   99  \n",
      "用户                                \n",
      "0   NaN  2.0  1.0  NaN  1.0  NaN  \n",
      "1   2.0  NaN  1.0  1.0  NaN  NaN  \n",
      "2   NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "3   3.0  NaN  NaN  NaN  NaN  NaN  \n",
      "4   NaN  NaN  NaN  NaN  1.0  1.0  \n",
      "5   NaN  2.0  NaN  NaN  NaN  1.0  \n",
      "6   NaN  NaN  1.0  NaN  NaN  NaN  \n",
      "7   NaN  NaN  1.0  NaN  1.0  NaN  \n",
      "8   NaN  NaN  3.0  NaN  1.0  1.0  \n",
      "9   2.0  3.0  NaN  2.0  1.0  NaN  \n",
      "10  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "11  2.0  NaN  NaN  NaN  NaN  1.0  \n",
      "12  4.0  2.0  1.0  NaN  2.0  NaN  \n",
      "13  1.0  NaN  NaN  NaN  NaN  NaN  \n",
      "14  NaN  2.0  NaN  NaN  1.0  NaN  \n",
      "15  NaN  NaN  1.0  1.0  3.0  NaN  \n",
      "16  3.0  NaN  NaN  NaN  3.0  1.0  \n",
      "17  NaN  2.0  NaN  1.0  NaN  NaN  \n",
      "18  NaN  NaN  NaN  1.0  1.0  2.0  \n",
      "19  NaN  NaN  NaN  NaN  4.0  NaN  \n",
      "20  4.0  NaN  NaN  1.0  NaN  NaN  \n",
      "21  NaN  NaN  NaN  NaN  NaN  1.0  \n",
      "22  NaN  2.0  NaN  NaN  4.0  1.0  \n",
      "23  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "24  2.0  NaN  5.0  NaN  1.0  1.0  \n",
      "25  1.0  NaN  NaN  2.0  NaN  NaN  \n",
      "26  5.0  NaN  1.0  NaN  NaN  NaN  \n",
      "27  NaN  NaN  NaN  NaN  1.0  NaN  \n",
      "28  1.0  2.0  NaN  NaN  NaN  NaN  \n",
      "29  4.0  NaN  NaN  1.0  NaN  1.0  \n",
      "\n",
      "[30 rows x 100 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 19\u001B[0m\n\u001B[0;32m     17\u001B[0m a4 \u001B[38;5;241m=\u001B[39m X_train\u001B[38;5;241m.\u001B[39mpivot_table(index\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m用户\u001B[39m\u001B[38;5;124m'\u001B[39m, columns\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m电影\u001B[39m\u001B[38;5;124m'\u001B[39m, values\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m打分\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28mprint\u001B[39m(a4)\n\u001B[1;32m---> 19\u001B[0m item_similarity_matrix \u001B[38;5;241m=\u001B[39m cosine_similarity(a4\u001B[38;5;241m.\u001B[39mT)\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28mprint\u001B[39m(item_similarity_matrix)\n",
      "File \u001B[1;32mD:\\Jupyter\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    209\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    210\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    211\u001B[0m         )\n\u001B[0;32m    212\u001B[0m     ):\n\u001B[1;32m--> 213\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    219\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    222\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    223\u001B[0m     )\n",
      "File \u001B[1;32mD:\\Jupyter\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1657\u001B[0m, in \u001B[0;36mcosine_similarity\u001B[1;34m(X, Y, dense_output)\u001B[0m\n\u001B[0;32m   1613\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001B[39;00m\n\u001B[0;32m   1614\u001B[0m \n\u001B[0;32m   1615\u001B[0m \u001B[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1653\u001B[0m \u001B[38;5;124;03m       [0.57..., 0.81...]])\u001B[39;00m\n\u001B[0;32m   1654\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1655\u001B[0m \u001B[38;5;66;03m# to avoid recursive import\u001B[39;00m\n\u001B[1;32m-> 1657\u001B[0m X, Y \u001B[38;5;241m=\u001B[39m check_pairwise_arrays(X, Y)\n\u001B[0;32m   1659\u001B[0m X_normalized \u001B[38;5;241m=\u001B[39m normalize(X, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m   1660\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m X \u001B[38;5;129;01mis\u001B[39;00m Y:\n",
      "File \u001B[1;32mD:\\Jupyter\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:155\u001B[0m, in \u001B[0;36mcheck_pairwise_arrays\u001B[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001B[0m\n\u001B[0;32m    152\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtype_float\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m Y \u001B[38;5;129;01mis\u001B[39;00m X \u001B[38;5;129;01mor\u001B[39;00m Y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 155\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y \u001B[38;5;241m=\u001B[39m check_array(\n\u001B[0;32m    156\u001B[0m         X,\n\u001B[0;32m    157\u001B[0m         accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n\u001B[0;32m    158\u001B[0m         dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[0;32m    159\u001B[0m         copy\u001B[38;5;241m=\u001B[39mcopy,\n\u001B[0;32m    160\u001B[0m         force_all_finite\u001B[38;5;241m=\u001B[39mforce_all_finite,\n\u001B[0;32m    161\u001B[0m         estimator\u001B[38;5;241m=\u001B[39mestimator,\n\u001B[0;32m    162\u001B[0m     )\n\u001B[0;32m    163\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    164\u001B[0m     X \u001B[38;5;241m=\u001B[39m check_array(\n\u001B[0;32m    165\u001B[0m         X,\n\u001B[0;32m    166\u001B[0m         accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    170\u001B[0m         estimator\u001B[38;5;241m=\u001B[39mestimator,\n\u001B[0;32m    171\u001B[0m     )\n",
      "File \u001B[1;32mD:\\Jupyter\\Lib\\site-packages\\sklearn\\utils\\validation.py:1049\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m   1043\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1044\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1045\u001B[0m         \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[0;32m   1046\u001B[0m     )\n\u001B[0;32m   1048\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[1;32m-> 1049\u001B[0m     _assert_all_finite(\n\u001B[0;32m   1050\u001B[0m         array,\n\u001B[0;32m   1051\u001B[0m         input_name\u001B[38;5;241m=\u001B[39minput_name,\n\u001B[0;32m   1052\u001B[0m         estimator_name\u001B[38;5;241m=\u001B[39mestimator_name,\n\u001B[0;32m   1053\u001B[0m         allow_nan\u001B[38;5;241m=\u001B[39mforce_all_finite \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow-nan\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1054\u001B[0m     )\n\u001B[0;32m   1056\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copy:\n\u001B[0;32m   1057\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_numpy_namespace(xp):\n\u001B[0;32m   1058\u001B[0m         \u001B[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Jupyter\\Lib\\site-packages\\sklearn\\utils\\validation.py:126\u001B[0m, in \u001B[0;36m_assert_all_finite\u001B[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m first_pass_isfinite:\n\u001B[0;32m    124\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m--> 126\u001B[0m _assert_all_finite_element_wise(\n\u001B[0;32m    127\u001B[0m     X,\n\u001B[0;32m    128\u001B[0m     xp\u001B[38;5;241m=\u001B[39mxp,\n\u001B[0;32m    129\u001B[0m     allow_nan\u001B[38;5;241m=\u001B[39mallow_nan,\n\u001B[0;32m    130\u001B[0m     msg_dtype\u001B[38;5;241m=\u001B[39mmsg_dtype,\n\u001B[0;32m    131\u001B[0m     estimator_name\u001B[38;5;241m=\u001B[39mestimator_name,\n\u001B[0;32m    132\u001B[0m     input_name\u001B[38;5;241m=\u001B[39minput_name,\n\u001B[0;32m    133\u001B[0m )\n",
      "File \u001B[1;32mD:\\Jupyter\\Lib\\site-packages\\sklearn\\utils\\validation.py:175\u001B[0m, in \u001B[0;36m_assert_all_finite_element_wise\u001B[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[0;32m    158\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n\u001B[0;32m    159\u001B[0m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[0;32m    160\u001B[0m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[0;32m    161\u001B[0m     msg_err \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    162\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not accept missing values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    163\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    173\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#estimators-that-handle-nan-values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    174\u001B[0m     )\n\u001B[1;32m--> 175\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
      "\u001B[1;31mValueError\u001B[0m: Input contains NaN."
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
