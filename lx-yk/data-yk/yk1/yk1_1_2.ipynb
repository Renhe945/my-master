{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# #数据字段说明\n",
    "# passengerid： 乘客 ID\n",
    "# class： 舱位等级 (1 = 1st, 2 = 2nd, 3 = 3rd)**\n",
    "# name： 乘客姓名\n",
    "# sex： 性别\n",
    "# age： 年龄\n",
    "# sibsp： 在船上的兄弟姐妹／配偶个数\n",
    "# parch： 在船上的父母／小孩个数\n",
    "# ticket： 船票信息\n",
    "# fare： 票价\n",
    "# cabin： 客舱\n",
    "# embarked： 登船港口 (C = Cherbourg, Q = Queenstown, S = Southampton)\n",
    "# survived:  变量预测为值 0 或 1（这里 1 表示幸存，0 表示遇难）"
   ],
   "id": "aeca5d31d666875c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-28T08:57:09.289223Z",
     "start_time": "2024-09-28T08:57:08.548538Z"
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 题目二、 乘客生还预测（40分）。\n",
    "# 使用泰坦尼克号数据集（train.csv），构建分类模型，并且调整超参数获取最佳模型，预测生存\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "a1=pd.read_csv(\"E:///python代码/lx-yk/data-yk/yk1/train.csv\")\n",
    "print(\"泰坦尼克号数据/n\",a1)\n",
    "\n",
    "# 1.获取数据，将字符类型的特征转换为数字型，将缺失值做均值处理（6分）\n",
    "'''将字符类型的特征转换为数字型'''\n",
    "for i in a1.columns:#对于a1列中的I\n",
    "    #如果列的数据类型是对象类型（通常是字符串），则对该列进行编码转换，将其从对象类型转换为整数编码。\n",
    "    if a1[i].dtype ==\"object\":#有一列包含字符串值\n",
    "        a1[i] = pd.factorize(a1[i])[0]#就使用factorize编码转换为整数编码形式。\n",
    "# a1\n",
    "# '''将缺失值做均值处理'''\n",
    "a1['Age']=a1['Age'].fillna(a1['Age'].mean())\n",
    "a1.isnull().sum()\n",
    "# 2.划分测试集与训练集，选择合适模型训练、预测。（5分）\n",
    "x=a1[['Age','Sex','Pclass']]\n",
    "y=a1['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "# 3.手动实现逻辑回归算法（5分）\n",
    "lr = LogisticRegression(max_iter=100)#最大的迭代次数\n",
    "lr.fit(X_train,y_train)\n",
    "yc1=lr.predict(X_test)\n",
    "\n",
    "\n",
    "# 4.至少使用2种算法进行数据建模，并设置合理的参数（5分）\n",
    "tree = DecisionTreeClassifier(min_samples_split=5, min_samples_leaf=4)\n",
    "tree.fit(X_train,y_train)\n",
    "yc2=tree.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# 5.选择合适评估指标评估模型。（6分）\n",
    "pg1=accuracy_score(y_test,yc1)\n",
    "print('逻辑回归评估/n',pg1)\n",
    "pg2=accuracy_score(y_test,yc2)\n",
    "print('决策树回归/n',pg2)\n",
    "\n",
    "逻辑回归混淆矩阵=confusion_matrix(y_test,yc1)\n",
    "print(\"逻辑回归混淆矩阵\",逻辑回归混淆矩阵)\n",
    "决策树回归混淆矩阵=confusion_matrix(y_test,yc2)\n",
    "print(\"决策树回归混淆矩阵\",决策树回归混淆矩阵)\n",
    "# 6.使用合适超参进行微调调整超参数，获取最佳模型。（8分）\n",
    "# 逻辑回归调参数\n",
    "lj={'fit_intercept':[True,False],'C':[0.1,1,10],'max_iter':[500,1000,2000]}\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf1 = GridSearchCV(estimator=lr,param_grid=lj,cv=5)\n",
    "clf1.fit(X_train, y_train)\n",
    "print(\"最优的参数\",clf1.best_estimator_)\n",
    "print(\"最佳得分\",clf1.best_score_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#决策树回归调参\n",
    "jc={'min_samples_split':[2,5,10], 'min_samples_leaf':[2,4,6],'max_depth':[3,4,5]}\n",
    "\n",
    "clf2 = GridSearchCV(estimator=tree, param_grid=jc,cv=5)\n",
    "clf2.fit(X_train, y_train)\n",
    "print(\"最优的参数\",clf2.best_estimator_)\n",
    "print(\"最佳得分\",clf2.best_score_)\n",
    "\n",
    "# 7.输出最优模型的权重系数，对样本进行预测，保存模型到本地（5分）\n",
    "zy1=clf1.best_estimator_\n",
    "print(\"逻辑回归权重系数\",zy1.coef_)\n",
    "zy2=clf2.best_estimator_\n",
    "print(\"随机森林权重系数\",zy2.feature_importances_)\n",
    "import joblib\n",
    "joblib.dump(zy1,'E:///python代码/lx-yk/data-yk/yk1/t1.pkl')\n",
    "joblib.dump(zy2,'E:///python代码/lx-yk/data-yk/yk1/t2.pkl')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "泰坦尼克号数据/n      PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "..           ...       ...     ...   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                    Name     Sex   Age  SibSp  \\\n",
      "0                                Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Thayer)  female  38.0      1   \n",
      "2                                 Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3           Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                               Allen, Mr. William Henry    male  35.0      0   \n",
      "..                                                   ...     ...   ...    ...   \n",
      "886                                Montvila, Rev. Juozas    male  27.0      0   \n",
      "887                         Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "888             Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "889                                Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                  Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked  \n",
      "0        0         A/5 21171   7.2500   NaN        S  \n",
      "1        0          PC 17599  71.2833   C85        C  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3        0            113803  53.1000  C123        S  \n",
      "4        0            373450   8.0500   NaN        S  \n",
      "..     ...               ...      ...   ...      ...  \n",
      "886      0            211536  13.0000   NaN        S  \n",
      "887      0            112053  30.0000   B42        S  \n",
      "888      2        W./C. 6607  23.4500   NaN        S  \n",
      "889      0            111369  30.0000  C148        C  \n",
      "890      0            370376   7.7500   NaN        Q  \n",
      "\n",
      "[891 rows x 12 columns]\n",
      "逻辑回归评估/n 0.8100558659217877\n",
      "决策树回归/n 0.8100558659217877\n",
      "逻辑回归混淆矩阵 [[91 14]\n",
      " [20 54]]\n",
      "决策树回归混淆矩阵 [[91 14]\n",
      " [20 54]]\n",
      "最优的参数 LogisticRegression(C=1, max_iter=500)\n",
      "最佳得分 0.7920614596670934\n",
      "最优的参数 DecisionTreeClassifier(max_depth=5, min_samples_leaf=4)\n",
      "最佳得分 0.8075839653304442\n",
      "逻辑回归权重系数 [[-0.02593304  2.47316185 -1.03478198]]\n",
      "随机森林权重系数 [0.16657865 0.60508784 0.22833351]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['E:///python代码/lx-yk/data-yk/yk1/t2.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
