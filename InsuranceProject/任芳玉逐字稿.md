
面试官您好，我叫任芳玉，从事大数据行业已经有5年了。在这期间，我熟练的运用Flink、Hadoop、Spark等大数据框架，
以及一些数据传输通道Kafka、Sqoop、Flume，
开发语言的话主要使用java和python java主要用于写一些flinksql 做一些flink项目。然后pyhon主要用于爬虫，数据的清洗、脱敏。
无论是实时数仓还是离线数仓，我都有丰富的实践经验。以上就是我的自我介绍，谢谢面试官

# 1. 最近的项目介绍（需求）

我最近做的项目是一个关于实时电商数仓的项目。
嗯这个项目是基于cdh 作为数据的底座，flink做的计算引擎，主要的使用cdc seatunnel 实现电商平台对海量数据的实时采集和传输，
运用成熟的分层架构，包括 ODS 层、DIM 层、DWD 层、DWS 层以及 ADS 层（~~如果在公司实时数据是不分层的~~）。ODS 层作为源数据然后不做处理。DIM 层创建事实与维度。DWD 层，明细数据层，对 ODS 层流入数据做深度清洗，去重；~~使逻辑更加清晰~~。DWS 层，汇总数据层，按业务所需要求对DWD 层数据聚合。ADS 层，面向应用层，直接连接实时数据大屏（苏格大屏）
~~我主要负责DIM层、DWD层、DWS层的开发构建~~
我主要负责的是ADS层的指标开发；


# 2. 项目难点及原因（难点）
优化措施：任务非常多
电商业务实时性要求高，尤其在大促期间，订单、用户行为数据非常多，既要保证数据快速流入处理，又要确保数据准确无误，稍有偏差就影响决策。如实时订单数据延迟或错误
原因在于多源数据产生速率不均，各业务系统数据质量参差不齐，并且实时处理架构在高并发下负载压力大，易出现数据丢失或处理不及时。

# 3. 解决方法（解决）
对 Flink 集群展开深度优化，精细调整任务并行度，根据实时流量动态分配资源，确保集群在高负载下仍能高效运行。同时，结合 Kafka 构建稳固的缓冲队列，让数据在进入 Flink 处理流程前有一个 “缓冲地带”，依数据优先级有序排列，保障关键数据优先处理。此外，充分利用 Flink 自身的 Checkpoint 机制，设置合理的 Checkpoint 间隔，在出现故障时能够快速从最近的稳定状态恢复，确保数据完整性与准确性。
针对网络不稳定等外部因素，引入智能监控与自动修复系统，实时监测 Flink 任务运行状态、一旦发现异常，立即启动自动修复程序，尝试重新连接、调整资源分配等操作，最大限度降低故障对数据处理的影响，保障 Flink 实时处理流程的稳定性与可靠性。



# 4. 项目中做过哪些优化，效果怎么样？（优化）
对 Flink 处理后存储在 Hive 中的数据进行分区优化，紧密围绕业务常用查询维度，像时间、地域等进行分区，大幅减少不必要的数据扫描。同时，优化 Hive 查询语句，添加合适索引，调整连接，大大减少复杂查询响应时间，运营人员生成报表的速度得到提高。


# 5. 对新趋势新技术的了解及应用（双新）
当下，大数据领域新趋势不断涌现。如实时数仓领域，云原生架构正逐渐普及，它能提供弹性可扩展资源。在本项目中，后续可探索将大数据仓库迁移至云平台，利用云的按需付费、快速部署特性，降低运维成本，提升资源利用效率。


------------------------------------------------------------------------------------
在项目中我做了哪些突出的优化

在flink做过哪些优化：

项目的技术栈：
为什么要用kafka：高吞吐，分布式架构，持久性，实时性
kafka会不会造成数据丢失：
数据迟到是怎么解决：

可能会问
日志数据是使用MongoDB获取的，业务数据是通过ETL 获取的

上家公司15k，期望薪资16k,

离职原因：项目已完工，新项目暂时接不到，空窗期比较长
公司规模太小，项目类型有限，但随着行业的快速发展，无法继续提供足够的学习与成长机会。所以为了能在行业中持续进步，我决定离职（备4；）

三个大数据，一个项目经理，一个前端，一个后端，一个运维，一个测试
   
数据量：每天200G，
7台虚拟机，64核，每台128内存，10t硬盘，

维度就是有一些省份地区，商品品类，店铺，
事实我们分互动域，交易域，用户域这些

 flink的背压什么情况?如何处理Flink中的背压问题？
 背压是在流式数据处理系统中，下游算子处理数据的速度跟不上上游算子发送数据的速度
 优化数据源,优化算子性能,增加并行度



#                     可能会问的问题：（用自己的话总结）
shell 中的单引号和双引号有什么区别？
单引号不取变量值；双引号取变量值；（反引号，执行引号中的命令）；
hdfs中的读写流程
写：
   使用client上传请求，通过rpc 与 namenode 建立通信，使用namenode检查目录文件和父目录它存不存在，确定能不能上传
   client请求第一个block上传到哪些服务器上，namenode 根据配置分配可用的datanode
   client向其中的一台datanode -A-上传数据，A收到请求后依次调用 B、C的数据传输通道。
   client将第一个数据块packet为单位依次传给A->b->c,A每传一个packet呐就放入应答队列中等着
   数据在通道中传输，反向逐个发送ack，最终由A将pipeline ack 发送给client
   一个数据块传输完成后，处理恩科再次请求namenode传给下一个数据块。
读：
   client向NameNode发送RPC请求。请求文件block的位置；
   NameNode 收到请求后检查权限和文件，符合则返回部分或全部 block 列表及含副本的 DataNode 地址，按集群拓扑结构与客户端距离排序，近的靠前，超时汇报的 DataNode 状态为 stale 的靠后。
    Client 选靠前的 DataNode 读取 block，如果客户端本身是 DataNode 则本地直接获取（短路读取特性。
    底层建立 Socket Stream（FSDataInputStream），重复调用 read 方法读完块数据。
    读完列表 block 后，如果文件未读完，客户端继续向 NameNode 获取下一批 block 列表。
    读完一个 block 进行 checksum 验证，如果读取 DataNode 出错，客户端通知 NameNode，从下一个有该 block 副本的 DataNode 继续读。
    read 方法并行读取 block 信息，NameNode 只返回 DataNode 地址，不返回数据。
    最终读取的所有 block 合并成完整文件
# HDFS在读取文件的时候，如果其中一个块突然损坏了怎么办
客户端读取完DataNode上的块之后会进行checksum 验证（也就是把客户端读取到本地的块与HDFS上的原始块进行校验）
如果发现校验结果不一致，客户端会通知NameNode，然后再从下一个拥有该block副本的DataNode继续读
# HDFS在上传文件的时候，如果其中一个DataNode突然挂掉了怎么办


















